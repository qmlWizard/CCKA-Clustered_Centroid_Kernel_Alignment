{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "np.random.seed(1359)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_circular_data(num_sectors):\n",
    "    \"\"\"Generate datapoints arranged in an even circle.\"\"\"\n",
    "    center_indices = np.array(range(0, num_sectors))\n",
    "    sector_angle = 2 * np.pi / num_sectors\n",
    "    angles = (center_indices + 0.5) * sector_angle\n",
    "    x = 0.7 * np.cos(angles)\n",
    "    y = 0.7 * np.sin(angles)\n",
    "    labels = 2 * np.remainder(np.floor_divide(angles, sector_angle), 2) - 1\n",
    "\n",
    "    return x, y, labels\n",
    "\n",
    "\n",
    "def make_double_cake_data(num_sectors):\n",
    "    x1, y1, labels1 = _make_circular_data(num_sectors)\n",
    "    x2, y2, labels2 = _make_circular_data(num_sectors)\n",
    "\n",
    "    # x and y coordinates of the datapoints\n",
    "    x = np.hstack([x1, 0.5 * x2])\n",
    "    y = np.hstack([y1, 0.5 * y2])\n",
    "\n",
    "    # Canonical form of dataset\n",
    "    X = np.vstack([x, y]).T\n",
    "\n",
    "    labels = np.hstack([labels1, -1 * labels2])\n",
    "\n",
    "    # Canonical form of labels\n",
    "    Y = labels.astype(int)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_double_cake_data(X, Y, ax, num_sectors=None):\n",
    "    \"\"\"Plot double cake data and corresponding sectors.\"\"\"\n",
    "    x, y = X.T\n",
    "    cmap = mpl.colors.ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax.scatter(x, y, c=Y, cmap=cmap, s=25, marker=\"s\")\n",
    "\n",
    "    if num_sectors is not None:\n",
    "        sector_angle = 360 / num_sectors\n",
    "        for i in range(num_sectors):\n",
    "            color = [\"#FF0000\", \"#0000FF\"][(i % 2)]\n",
    "            other_color = [\"#FF0000\", \"#0000FF\"][((i + 1) % 2)]\n",
    "            ax.add_artist(\n",
    "                mpl.patches.Wedge(\n",
    "                    (0, 0),\n",
    "                    1,\n",
    "                    i * sector_angle,\n",
    "                    (i + 1) * sector_angle,\n",
    "                    lw=0,\n",
    "                    color=color,\n",
    "                    alpha=0.1,\n",
    "                    width=0.5,\n",
    "                )\n",
    "            )\n",
    "            ax.add_artist(\n",
    "                mpl.patches.Wedge(\n",
    "                    (0, 0),\n",
    "                    0.5,\n",
    "                    i * sector_angle,\n",
    "                    (i + 1) * sector_angle,\n",
    "                    lw=0,\n",
    "                    color=other_color,\n",
    "                    alpha=0.1,\n",
    "                )\n",
    "            )\n",
    "            ax.set_xlim(-1, 1)\n",
    "\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_sectors = 3\n",
    "X, Y = make_double_cake_data(num_sectors)\n",
    "\n",
    "ax = plot_double_cake_data(X, Y, plt.gca(), num_sectors=num_sectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "\n",
    "def layer(x, params, wires, i0=0, inc=1):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    i = i0\n",
    "    for j, wire in enumerate(wires):\n",
    "        qml.Hadamard(wires=[wire])\n",
    "        qml.RZ(x[i % len(x)], wires=[wire])\n",
    "        i += inc\n",
    "        qml.RY(params[0, j], wires=[wire])\n",
    "\n",
    "    qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])\n",
    "    \n",
    "def ansatz(x, params, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    for j, layer_params in enumerate(params):\n",
    "        layer(x, layer_params, wires, i0=j * len(wires))\n",
    "\n",
    "\n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "\n",
    "def random_params(num_wires, num_layers):\n",
    "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
    "    return np.random.uniform(0, 2 * np.pi, (num_layers, 2, num_wires), requires_grad=True)\n",
    "\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=5, shots=None)\n",
    "wires = dev.wires.tolist()\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2, params):\n",
    "    ansatz(x1, params, wires=wires)\n",
    "    adjoint_ansatz(x2, params, wires=wires)\n",
    "    return qml.probs(wires=wires)\n",
    "\n",
    "def kernel(x1, x2, params):\n",
    "    return kernel_circuit(x1, x2, params)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = random_params(num_wires=5, num_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel value between the first and second datapoint is 0.030\n"
     ]
    }
   ],
   "source": [
    "kernel_value = kernel(X[0], X[1], init_params)\n",
    "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439.696098</td>\n",
       "      <td>19.413507</td>\n",
       "      <td>-346.143990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301.383044</td>\n",
       "      <td>-57.311965</td>\n",
       "      <td>-376.260670</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430.294184</td>\n",
       "      <td>-354.869263</td>\n",
       "      <td>298.677702</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284.805397</td>\n",
       "      <td>238.235096</td>\n",
       "      <td>-385.805970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.287708</td>\n",
       "      <td>153.283479</td>\n",
       "      <td>-14.750879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>479.643035</td>\n",
       "      <td>154.173968</td>\n",
       "      <td>319.246503</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-246.038547</td>\n",
       "      <td>452.936892</td>\n",
       "      <td>-77.778271</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>224.898409</td>\n",
       "      <td>243.624809</td>\n",
       "      <td>133.921752</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-88.257300</td>\n",
       "      <td>-95.365191</td>\n",
       "      <td>-108.997893</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>423.726271</td>\n",
       "      <td>-411.643972</td>\n",
       "      <td>440.629865</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-86.847334</td>\n",
       "      <td>-384.556724</td>\n",
       "      <td>-469.200824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-349.525195</td>\n",
       "      <td>-156.933577</td>\n",
       "      <td>466.004075</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>375.626612</td>\n",
       "      <td>480.092735</td>\n",
       "      <td>-259.876972</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202.989439</td>\n",
       "      <td>-150.204021</td>\n",
       "      <td>-109.820333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-337.904930</td>\n",
       "      <td>-389.856970</td>\n",
       "      <td>-438.819968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-223.776098</td>\n",
       "      <td>96.666276</td>\n",
       "      <td>-303.012726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>216.370785</td>\n",
       "      <td>477.633066</td>\n",
       "      <td>252.719185</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>485.150237</td>\n",
       "      <td>-272.181061</td>\n",
       "      <td>131.553193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201.443498</td>\n",
       "      <td>-271.229690</td>\n",
       "      <td>-85.949118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-413.831396</td>\n",
       "      <td>-82.462245</td>\n",
       "      <td>-69.029037</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-289.086661</td>\n",
       "      <td>-126.231045</td>\n",
       "      <td>76.972061</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-16.858698</td>\n",
       "      <td>-229.727702</td>\n",
       "      <td>-102.237460</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>309.215363</td>\n",
       "      <td>369.327505</td>\n",
       "      <td>481.992842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-283.932808</td>\n",
       "      <td>-6.211313</td>\n",
       "      <td>-461.115848</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>144.146493</td>\n",
       "      <td>96.179999</td>\n",
       "      <td>-66.263348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>160.291210</td>\n",
       "      <td>-446.318567</td>\n",
       "      <td>454.031324</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>263.753590</td>\n",
       "      <td>-465.830534</td>\n",
       "      <td>-4.952933</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>370.416311</td>\n",
       "      <td>-44.509487</td>\n",
       "      <td>409.740914</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>448.602480</td>\n",
       "      <td>-469.074656</td>\n",
       "      <td>-423.209174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>499.796157</td>\n",
       "      <td>61.200472</td>\n",
       "      <td>-90.579416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-113.107626</td>\n",
       "      <td>-253.594310</td>\n",
       "      <td>-385.202308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-329.178813</td>\n",
       "      <td>-402.306043</td>\n",
       "      <td>-436.299142</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>423.303156</td>\n",
       "      <td>69.976475</td>\n",
       "      <td>-14.350256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>339.897233</td>\n",
       "      <td>-208.280841</td>\n",
       "      <td>16.131364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-357.712703</td>\n",
       "      <td>190.368616</td>\n",
       "      <td>-242.765988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-408.187759</td>\n",
       "      <td>332.411642</td>\n",
       "      <td>479.566640</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>27.872689</td>\n",
       "      <td>-78.602099</td>\n",
       "      <td>-21.157998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>107.012896</td>\n",
       "      <td>397.028662</td>\n",
       "      <td>168.131868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-309.799686</td>\n",
       "      <td>85.015438</td>\n",
       "      <td>228.394035</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>331.385797</td>\n",
       "      <td>20.641507</td>\n",
       "      <td>-108.238508</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>245.277293</td>\n",
       "      <td>-423.692279</td>\n",
       "      <td>142.980391</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>401.948075</td>\n",
       "      <td>181.179440</td>\n",
       "      <td>-391.487480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-114.329413</td>\n",
       "      <td>-170.450779</td>\n",
       "      <td>110.731770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-320.691415</td>\n",
       "      <td>28.656622</td>\n",
       "      <td>394.254391</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-258.832388</td>\n",
       "      <td>-466.637847</td>\n",
       "      <td>222.151643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-120.151474</td>\n",
       "      <td>-107.663463</td>\n",
       "      <td>-468.727808</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>213.383936</td>\n",
       "      <td>460.691895</td>\n",
       "      <td>-260.012118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-184.155677</td>\n",
       "      <td>-36.228878</td>\n",
       "      <td>378.483254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-139.702691</td>\n",
       "      <td>-403.997244</td>\n",
       "      <td>-338.029083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>433.900195</td>\n",
       "      <td>-75.429910</td>\n",
       "      <td>-22.786690</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1   feature_2   feature_3  target\n",
       "0   439.696098   19.413507 -346.143990       1\n",
       "1   301.383044  -57.311965 -376.260670      -1\n",
       "2   430.294184 -354.869263  298.677702      -1\n",
       "3   284.805397  238.235096 -385.805970       1\n",
       "4    19.287708  153.283479  -14.750879       1\n",
       "5   479.643035  154.173968  319.246503      -1\n",
       "6  -246.038547  452.936892  -77.778271      -1\n",
       "7   224.898409  243.624809  133.921752      -1\n",
       "8   -88.257300  -95.365191 -108.997893      -1\n",
       "9   423.726271 -411.643972  440.629865      -1\n",
       "10  -86.847334 -384.556724 -469.200824       1\n",
       "11 -349.525195 -156.933577  466.004075      -1\n",
       "12  375.626612  480.092735 -259.876972      -1\n",
       "13  202.989439 -150.204021 -109.820333      -1\n",
       "14 -337.904930 -389.856970 -438.819968       1\n",
       "15 -223.776098   96.666276 -303.012726       1\n",
       "16  216.370785  477.633066  252.719185      -1\n",
       "17  485.150237 -272.181061  131.553193       1\n",
       "18  201.443498 -271.229690  -85.949118      -1\n",
       "19 -413.831396  -82.462245  -69.029037      -1\n",
       "20 -289.086661 -126.231045   76.972061      -1\n",
       "21  -16.858698 -229.727702 -102.237460      -1\n",
       "22  309.215363  369.327505  481.992842       1\n",
       "23 -283.932808   -6.211313 -461.115848      -1\n",
       "24  144.146493   96.179999  -66.263348       1\n",
       "25  160.291210 -446.318567  454.031324      -1\n",
       "26  263.753590 -465.830534   -4.952933      -1\n",
       "27  370.416311  -44.509487  409.740914      -1\n",
       "28  448.602480 -469.074656 -423.209174       1\n",
       "29  499.796157   61.200472  -90.579416       1\n",
       "30 -113.107626 -253.594310 -385.202308       1\n",
       "31 -329.178813 -402.306043 -436.299142      -1\n",
       "32  423.303156   69.976475  -14.350256       1\n",
       "33  339.897233 -208.280841   16.131364       1\n",
       "34 -357.712703  190.368616 -242.765988       1\n",
       "35 -408.187759  332.411642  479.566640      -1\n",
       "36   27.872689  -78.602099  -21.157998       1\n",
       "37  107.012896  397.028662  168.131868       1\n",
       "38 -309.799686   85.015438  228.394035      -1\n",
       "39  331.385797   20.641507 -108.238508      -1\n",
       "40  245.277293 -423.692279  142.980391      -1\n",
       "41  401.948075  181.179440 -391.487480       1\n",
       "42 -114.329413 -170.450779  110.731770       1\n",
       "43 -320.691415   28.656622  394.254391      -1\n",
       "44 -258.832388 -466.637847  222.151643       1\n",
       "45 -120.151474 -107.663463 -468.727808      -1\n",
       "46  213.383936  460.691895 -260.012118      -1\n",
       "47 -184.155677  -36.228878  378.483254       1\n",
       "48 -139.702691 -403.997244 -338.029083       1\n",
       "49  433.900195  -75.429910  -22.786690      -1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.classification_data import checkerboard_data, linear_data, hidden_manifold_data, power_line_data, microgrid_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = checkerboard_data(5, 100)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(data[[col for col in data.columns if col != 'target']].values.tolist())\n",
    "target = np.asarray(data['target'].values.tolist())\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel value between the first and second datapoint is 0.051\n"
     ]
    }
   ],
   "source": [
    "kernel_value = kernel(x_train[0], x_train[5], init_params)\n",
    "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.001 0.028 ... 0.    0.    0.003]\n",
      " [0.001 1.    0.071 ... 0.061 0.075 0.003]\n",
      " [0.028 0.071 1.    ... 0.017 0.086 0.042]\n",
      " ...\n",
      " [0.    0.061 0.017 ... 1.    0.03  0.007]\n",
      " [0.    0.075 0.086 ... 0.03  1.    0.009]\n",
      " [0.003 0.003 0.042 ... 0.007 0.009 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "init_kernel = lambda x1, x2: kernel(x1, x2, init_params)\n",
    "K_init = qml.kernels.square_kernel_matrix(x_train, init_kernel, assume_normalized_kernel=True)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(K_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel=lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, init_kernel)).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the kernel with random parameters is 1.000\n"
     ]
    }
   ],
   "source": [
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)\n",
    "\n",
    "\n",
    "accuracy_init = accuracy(svm, x_train, y_train)\n",
    "print(f\"The accuracy of the kernel with random parameters is {accuracy_init:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the kernel with random parameters is 0.500\n"
     ]
    }
   ],
   "source": [
    "accuracy_init = accuracy(svm, x_test, y_test)\n",
    "print(f\"The accuracy of the kernel with random parameters is {accuracy_init:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(classifier, ax, N_gridpoints=14):\n",
    "    _xx, _yy = np.meshgrid(np.linspace(-1, 1, N_gridpoints), np.linspace(-1, 1, N_gridpoints))\n",
    "\n",
    "    _zz = np.zeros_like(_xx)\n",
    "    for idx in np.ndindex(*_xx.shape):\n",
    "        _zz[idx] = classifier.predict(np.array([_xx[idx], _yy[idx]])[np.newaxis, :])\n",
    "\n",
    "    plot_data = {\"_xx\": _xx, \"_yy\": _yy, \"_zz\": _zz}\n",
    "    ax.contourf(\n",
    "        _xx,\n",
    "        _yy,\n",
    "        _zz,\n",
    "        cmap=mpl.colors.ListedColormap([\"#FF0000\", \"#0000FF\"]),\n",
    "        alpha=0.2,\n",
    "        levels=[-1, 0, 1],\n",
    "    )\n",
    "    plot_double_cake_data(X, Y, ax)\n",
    "\n",
    "    return plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel-target alignment for our dataset and random parameters is 0.146\n"
     ]
    }
   ],
   "source": [
    "kta_init = qml.kernels.target_alignment(x_train, y_train, init_kernel, assume_normalized_kernel=True)\n",
    "print(f\"The kernel-target alignment for our dataset and random parameters is {kta_init:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 - Alignment = 0.148\n",
      "Step 100 - Alignment = 0.152\n",
      "Step 150 - Alignment = 0.154\n",
      "Step 200 - Alignment = 0.156\n",
      "Step 250 - Alignment = 0.159\n",
      "Step 300 - Alignment = 0.161\n",
      "Step 350 - Alignment = 0.162\n",
      "Step 400 - Alignment = 0.163\n",
      "Step 450 - Alignment = 0.164\n",
      "Step 500 - Alignment = 0.164\n"
     ]
    }
   ],
   "source": [
    "def target_alignment(\n",
    "    X,\n",
    "    Y,\n",
    "    kernel,\n",
    "    assume_normalized_kernel=False,\n",
    "    rescale_class_labels=True,\n",
    "):\n",
    "    \"\"\"Kernel-target alignment between kernel and labels.\"\"\"\n",
    "\n",
    "    K = qml.kernels.square_kernel_matrix(\n",
    "        X,\n",
    "        kernel,\n",
    "        assume_normalized_kernel=assume_normalized_kernel,\n",
    "    )\n",
    "\n",
    "    if rescale_class_labels:\n",
    "        nplus = np.count_nonzero(np.array(Y) == 1)\n",
    "        nminus = len(Y) - nplus\n",
    "        _Y = np.array([y / nplus if y == 1 else y / nminus for y in Y])\n",
    "    else:\n",
    "        _Y = np.array(Y)\n",
    "\n",
    "    T = np.outer(_Y, _Y)\n",
    "    inner_product = np.sum(K * T)\n",
    "    norm = np.sqrt(np.sum(K * K) * np.sum(T * T))\n",
    "    inner_product = inner_product / norm\n",
    "\n",
    "    return inner_product\n",
    "\n",
    "\n",
    "params = init_params\n",
    "opt = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "for i in range(500):\n",
    "    # Choose subset of datapoints to compute the KTA on.\n",
    "    subset = np.random.choice(list(range(len(x_train))), 4)\n",
    "    # Define the cost function for optimization\n",
    "    cost = lambda _params: -target_alignment(\n",
    "        x_train[subset],\n",
    "        y_train[subset],\n",
    "        lambda x1, x2: kernel(x1, x2, _params),\n",
    "        assume_normalized_kernel=True,\n",
    "    )\n",
    "    # Optimization step\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "    # Report the alignment on the full dataset every 50 steps.\n",
    "    if (i + 1) % 50 == 0:\n",
    "        current_alignment = target_alignment(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "        print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a kernel with the trained parameter baked into it.\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "# Second create a kernel matrix function using the trained kernel.\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "# Note that SVC expects the kernel argument to be a kernel matrix function.\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 1.000\n"
     ]
    }
   ],
   "source": [
    "accuracy_trained = accuracy(svm_trained, x_train, y_train)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 0.600\n"
     ]
    }
   ],
   "source": [
    "accuracy_trained = accuracy(svm_trained, x_test, y_test)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgreedy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
