{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from utils.classification_data import linear_data, checkerboard_data, power_line_data, microgrid_data, make_double_cake_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pennylane import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib as mpl\n",
    "from pennylane import numpy as np\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "from utils.classification_data import plot_and_save, make_double_cake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'iris'\n",
    "n_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = make_double_cake_data(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data/balanced_quantum_dataset.csv')\n",
    "#features = np.asarray(data.drop(columns=['label']))\n",
    "#target = np.asarray(data['label'])\n",
    "\n",
    "X, x_test, Y, y_test = train_test_split(\n",
    "    features, target, test_size=0.8, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data:  (50, 2)\n",
      "training_labels:  (50,)\n",
      "test_data:  (49, 2)\n",
      "test_labels:  49\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data_filepath, num_train=10, num_test=10, balanced=False):\n",
    "    \"\"\"\n",
    "    Quick function used to split data into test and training samples.\n",
    "\n",
    "    Args:\n",
    "        data_filepath (str): filepath to read the data from.\n",
    "        num_train (int): number of training samples.\n",
    "        num_test (int): number of test samples.\n",
    "        balanced (bool): whether there are an equal number of each class represented.\n",
    "\n",
    "    Returns:\n",
    "        X_train (np.ndarray): training sample features.\n",
    "        y_train (np.ndarray): testing sample features.\n",
    "        X_test (np.ndarray): training sample labels.\n",
    "        y_test (np.ndarray): testing sample labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_filepath, sep=\",\")\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    if balanced:\n",
    "        unique_labels = df.iloc[:, -1].unique()\n",
    "\n",
    "        for label in unique_labels:\n",
    "            label_indices = df[df.iloc[:, -1] == label].index.to_numpy()\n",
    "            np.random.shuffle(label_indices)\n",
    "\n",
    "            train_count = min(num_train, len(label_indices))\n",
    "            test_count = min(num_test, len(label_indices) - train_count)\n",
    "\n",
    "            train_indices.extend(label_indices[:train_count])\n",
    "            test_indices.extend(label_indices[train_count : train_count + test_count])\n",
    "\n",
    "    else:\n",
    "        indices = np.arange(len(df))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_indices = indices[:num_train]\n",
    "        test_indices = indices[num_train : num_train + num_test]\n",
    "\n",
    "    X_train = df.iloc[train_indices, :-1].to_numpy()\n",
    "    y_train = df.iloc[train_indices, -1].to_numpy()\n",
    "\n",
    "    X_test = df.iloc[test_indices, :-1].to_numpy()\n",
    "    y_test = df.iloc[test_indices, -1].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Load the dataset and split into train and test sets\n",
    "DATA_FILEPATH = \"data/checherboard_paper.csv\"\n",
    "X, Y, x_test, y_test = train_test_split(\n",
    "    DATA_FILEPATH, num_train=50, num_test=50\n",
    ")\n",
    "# The proportion of train and test datapoints can be adjusted as needed.\n",
    "# Doing some quick checks.\n",
    "print(\"training_data: \", X.shape)\n",
    "print(\"training_labels: \", Y.shape)\n",
    "print(\"test_data: \", x_test.shape)\n",
    "print(\"test_labels: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "circuit_executions = 0\n",
    "def layer(x, params, wires, i0=0, inc=1):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    i = i0\n",
    "    for j, wire in enumerate(wires):\n",
    "        qml.Hadamard(wires=[wire])\n",
    "        qml.RZ(x[i % len(x)], wires=[wire])\n",
    "        i += inc\n",
    "        qml.RY(params[0, j], wires=[wire])\n",
    "\n",
    "    qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])\n",
    "\n",
    "def ansatz(x, params, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    for j, layer_params in enumerate(params):\n",
    "        layer(x, layer_params, wires, i0=j * len(wires))\n",
    "\n",
    "\n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "\n",
    "def random_params(num_wires, num_layers):\n",
    "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
    "    return np.random.uniform(0, 2 * np.pi, (num_layers, 2, num_wires), requires_grad=True)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=3, shots=None)\n",
    "wires = dev.wires.tolist()\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2, params):\n",
    "    global circuit_executions\n",
    "    circuit_executions += 1\n",
    "    ansatz(x1, params, wires=wires)\n",
    "    adjoint_ansatz(x2, params, wires=wires)\n",
    "    return qml.probs(wires=wires)\n",
    "\n",
    "def kernel(x1, x2, params):\n",
    "    return kernel_circuit(x1, x2, params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = random_params(num_wires=3, num_layers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel value between the first and second datapoint is 0.482\n"
     ]
    }
   ],
   "source": [
    "kernel_value = kernel(X[0], X[1], params)\n",
    "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(Y)\n",
    "n_clusters = 8\n",
    "\n",
    "centroids = []\n",
    "class_centroids = []\n",
    "centroid_labels = []\n",
    "for c in classes:\n",
    "    class_data = X[np.where(Y == c)[0]]\n",
    "    centroids.append(np.mean(class_data, axis=0))\n",
    "    class_centroids.append([np.mean(cluster, axis=0) for cluster in np.array_split(class_data, n_clusters)])\n",
    "    centroid_labels.extend([[c] * n_clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_kernel_matrix(X, centroid, ckernel):\n",
    "    \n",
    "    kernel_matrix = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        kernel_matrix.append(ckernel(centroid, X[i]))\n",
    "\n",
    "    return np.array(kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def centroid_target_alignment(X, Y, centroid, kernel, l = 0.1, assume_normalized_kernel=False, rescale_class_labels=True):\n",
    "   \n",
    "    Y = np.asarray(Y)\n",
    "    K = centroid_kernel_matrix(X, centroid, kernel)\n",
    "    numerator = l * np.sum(Y * K)  \n",
    "    denominator = np.sqrt(np.sum(K**2) * np.sum(Y**2))\n",
    "\n",
    "    TA = numerator / denominator\n",
    "\n",
    "    return TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_kao(X, Y, centroid, kernel, params, lambda_kao = 0.01):\n",
    "    TA = centroid_target_alignment(X, Y, centroid, kernel)\n",
    "    r = lambda_kao * np.sum(params ** 2)\n",
    "    return 1 - TA + r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_co(X, Y, centroid, kernel, cl, lambda_kao = 0.01):\n",
    "    TA = centroid_target_alignment(X, Y, centroid, kernel)\n",
    "    r = np.sum(np.maximum(cl - 1, 0) - np.minimum(cl, 0))\n",
    "    return 1 - TA + r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_centroids = class_centroids[0]\n",
    "class2_centroids = class_centroids[1]\n",
    "\n",
    "centroid1_labels = centroid_labels[0]\n",
    "centroid2_labels = centroid_labels[1]\n",
    "\n",
    "centroid1 = centroids[0]\n",
    "centroid2 = centroids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment = 0.076\n"
     ]
    }
   ],
   "source": [
    "current_alignment = qml.kernels.target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "print(f\"Alignment = {current_alignment:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 0.571\n"
     ]
    }
   ],
   "source": [
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)\n",
    "\n",
    "accuracy_trained = accuracy(svm_trained, x_test, y_test)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "kao_class = 1\n",
    "kao_subclass = 1\n",
    "opt = qml.AdamOptimizer()\n",
    "opt_centroid = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "circuit_executions = 0\n",
    "#params = random_params(num_wires=6, num_layers=6)\n",
    "\n",
    "# Your provided arrays: centroids, class_centroids, and centroid_labels\n",
    "n_classes = len(classes)\n",
    "\n",
    "for i in range(1500):\n",
    "    \n",
    "    centroid_idx = kao_class - 1  # Index for the current class/centroid\n",
    "    cost = lambda _params: -loss_kao(\n",
    "            np.vstack(class_centroids),  # Access current class clusters\n",
    "            np.concatenate(centroid_labels),  # Labels for the current class\n",
    "            centroids[centroid_idx],        # Current centroid\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            _params\n",
    "        )\n",
    "    \n",
    "    centroid_cost = lambda _centroid: -loss_co(\n",
    "            class_centroids[centroid_idx],  # Access current class clusters\n",
    "            centroid_labels[centroid_idx],  # Labels for the current class\n",
    "            centroids[centroid_idx],        # Current centroid\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            _centroid\n",
    "        )\n",
    "\n",
    "    params = opt.step(cost, params)\n",
    "    centroids[centroid_idx] = opt_centroid.step(centroid_cost, centroids[centroid_idx])\n",
    "\n",
    "    for sub_centroid_idx in range(len(class_centroids[centroid_idx])):\n",
    "        class_centroids[centroid_idx][sub_centroid_idx] = opt_centroid.step(centroid_cost, class_centroids[centroid_idx][sub_centroid_idx])\n",
    "    kao_class = (kao_class % n_classes) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment = 0.093\n"
     ]
    }
   ],
   "source": [
    "current_alignment = qml.kernels.target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "print(f\"Alignment = {current_alignment:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# First create a kernel with the trained parameter baked into it.\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "\n",
    "# Second create a kernel matrix function using the trained kernel.\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "\n",
    "# Note that SVC expects the kernel argument to be a kernel matrix function.\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 0.740\n"
     ]
    }
   ],
   "source": [
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)\n",
    "\n",
    "accuracy_trained = accuracy(svm_trained, X, Y)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained 0.5918367346938775\n"
     ]
    }
   ],
   "source": [
    "accuracy_trained = accuracy(svm_trained, x_test, y_test)\n",
    "print(f\"The accuracy of a kernel with trained {accuracy_trained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "Circuit Executions: 14000\n",
      "Alignment = 0.154\n"
     ]
    }
   ],
   "source": [
    "circuit_executions = 0\n",
    "\n",
    "params = random_params(num_wires=3, num_layers=6)\n",
    "opt = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "for i in range(500):\n",
    "    # Choose subset of datapoints to compute the KTA on.\n",
    "    print(i)\n",
    "    subset = np.random.choice(list(range(len(X))), 8)\n",
    "    # Define the cost function for optimization\n",
    "    cost = lambda _params: -qml.kernels.target_alignment(\n",
    "        X[subset],\n",
    "        Y[subset],\n",
    "        lambda x1, x2: kernel(x1, x2, _params),\n",
    "        assume_normalized_kernel=True,\n",
    "    )\n",
    "    # Optimization step\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "    # Report the alignment on the full dataset every 50 steps.\n",
    "print(f\"Circuit Executions: {circuit_executions}\")\n",
    "current_alignment = qml.kernels.target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "print(f\"Alignment = {current_alignment:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# First create a kernel with the trained parameter baked into it.\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "\n",
    "# Second create a kernel matrix function using the trained kernel.\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "\n",
    "# Note that SVC expects the kernel argument to be a kernel matrix function.\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 0.840\n"
     ]
    }
   ],
   "source": [
    "accuracy_trained = accuracy(svm_trained, X, Y)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a kernel with trained parameters is 0.633\n"
     ]
    }
   ],
   "source": [
    "accuracy_trained = accuracy(svm_trained, x_test, y_test)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD scene created successfully!\n"
     ]
    }
   ],
   "source": [
    "from pxr import Usd, UsdGeom, Gf\n",
    "\n",
    "# Create a new USD stage (empty .usd file)\n",
    "stage = Usd.Stage.CreateNew(\"test_scene.usda\")\n",
    "\n",
    "# Define a root Xform (transform) for the stage\n",
    "xform = UsdGeom.Xform.Define(stage, \"/World\")\n",
    "xform.AddTranslateOp().Set(Gf.Vec3d(0, 0, 0))\n",
    "\n",
    "# Create a sphere under the root Xform\n",
    "sphere = UsdGeom.Sphere.Define(stage, \"/World/Sphere\")\n",
    "sphere.GetRadiusAttr().Set(1.0)\n",
    "\n",
    "# Create a cube under the root Xform\n",
    "cube = UsdGeom.Cube.Define(stage, \"/World/Cube\")\n",
    "cube.GetSizeAttr().Set(2.0)\n",
    "cube.AddTranslateOp().Set(Gf.Vec3d(3, 0, 0))\n",
    "\n",
    "# Save the stage\n",
    "stage.GetRootLayer().Save()\n",
    "\n",
    "print(\"USD scene created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgreedy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
