{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 21:55:27,970\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-15 21:55:28,623\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Custom Libraries\n",
    "from utils.model import Qkernel\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.agent import TrainModel\n",
    "\n",
    "# Backend Configuration\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Configs\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "data = np.load('checkerboard_dataset.npy', allow_pickle=True).item()\n",
    "x_train, x_test, y_train, y_test = data['x_train'], data['x_test'], data['y_train'], data['y_test']\n",
    "\n",
    "training_data = torch.tensor(x_train, dtype=torch.float32, requires_grad=True)\n",
    "testing_data = torch.tensor(x_test, dtype=torch.float32, requires_grad=True)\n",
    "training_labels = torch.tensor(y_train, dtype=torch.int)\n",
    "testing_labels = torch.tensor(y_test, dtype=torch.int)\n",
    "\n",
    "kernel = Qkernel(   \n",
    "                        device = config['qkernel']['device'], \n",
    "                        n_qubits = 4, \n",
    "                        trainable = True, \n",
    "                        input_scaling = True, \n",
    "                        data_reuploading = True, \n",
    "                        ansatz = 'embedding_paper', \n",
    "                        ansatz_layers = 5\n",
    "                    )\n",
    "    \n",
    "agent = TrainModel(\n",
    "                        kernel=kernel,\n",
    "                        training_data=training_data,\n",
    "                        training_labels=training_labels,\n",
    "                        testing_data=testing_data,\n",
    "                        testing_labels=testing_labels,\n",
    "                        optimizer= 'adam',\n",
    "                        lr= 0.1,\n",
    "                        epochs = 200,\n",
    "                        train_method= 'ccka',\n",
    "                        target_accuracy=0.95,\n",
    "                        get_alignment_every=10,  \n",
    "                        validate_every_epoch=None, \n",
    "                        base_path='.',\n",
    "                        lambda_kao=0.01,\n",
    "                        lambda_co=0.1,\n",
    "                        clusters=4\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Centroids:\n",
      " tensor([[0.4915, 0.4302, 0.4707, 0.5329, 0.4510],\n",
      "        [0.4466, 0.4058, 0.5046, 0.4990, 0.4453],\n",
      "        [0.5571, 0.5140, 0.5321, 0.4686, 0.4060]], requires_grad=True)\n",
      "Cluster Centroids:\n",
      " tensor([[0.4103, 0.4986, 0.4936, 0.7673, 0.7676],\n",
      "        [0.2456, 0.2066, 0.2970, 0.3154, 0.4583],\n",
      "        [0.6191, 0.4295, 0.7957, 0.7367, 0.2454],\n",
      "        [0.6221, 0.5363, 0.2217, 0.2414, 0.3570],\n",
      "        [0.5588, 0.4546, 0.7054, 0.3871, 0.6408],\n",
      "        [0.6754, 0.3836, 0.1603, 0.5244, 0.4380],\n",
      "        [0.2054, 0.3524, 0.6492, 0.8243, 0.3363],\n",
      "        [0.2660, 0.3906, 0.1646, 0.2390, 0.1198],\n",
      "        [0.9082, 0.7023, 0.8198, 0.2520, 0.1499],\n",
      "        [0.2482, 0.7609, 0.4719, 0.4069, 0.3340],\n",
      "        [0.5743, 0.3646, 0.5132, 0.8554, 0.4463],\n",
      "        [0.6616, 0.3239, 0.4460, 0.1415, 0.5916]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_centroids(train_data, train_labels, num_clusters_per_class):\n",
    "    unique_classes = torch.unique(train_labels)\n",
    "    num_classes = unique_classes.size(0)\n",
    "    \n",
    "    # Initialize tensors for main centroids and cluster centroids\n",
    "    main_centroids = []\n",
    "    cluster_centroids = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        # Get data points belonging to the current class\n",
    "        class_data = train_data[train_labels == cls]\n",
    "        \n",
    "        # Compute main centroid as the mean of all features for the class\n",
    "        main_centroid = class_data.mean(dim=0)\n",
    "        main_centroids.append(main_centroid)\n",
    "        \n",
    "        # K-Means-like cluster initialization for the class\n",
    "        n_samples = class_data.size(0)\n",
    "        if n_samples <= num_clusters_per_class:\n",
    "            # If not enough samples, use all data points as centroids\n",
    "            cluster_init = class_data\n",
    "        else:\n",
    "            # Randomly initialize cluster centroids\n",
    "            initial_indices = torch.randperm(n_samples)[:num_clusters_per_class]\n",
    "            cluster_init = class_data[initial_indices]\n",
    "            \n",
    "            # Iteratively refine centroids\n",
    "            for _ in range(5):  # Number of refinement iterations\n",
    "                distances = torch.cdist(class_data, cluster_init)  # Compute distances\n",
    "                cluster_assignments = distances.argmin(dim=1)  # Assign to nearest centroid\n",
    "                \n",
    "                # Update centroids to be the mean of assigned points\n",
    "                for i in range(num_clusters_per_class):\n",
    "                    cluster_points = class_data[cluster_assignments == i]\n",
    "                    if cluster_points.size(0) > 0:\n",
    "                        cluster_init[i] = cluster_points.mean(dim=0)\n",
    "        \n",
    "        cluster_centroids.append(cluster_init)\n",
    "    \n",
    "    # Stack the centroids into tensors\n",
    "    main_centroids = torch.stack(main_centroids, dim=0)\n",
    "    cluster_centroids = torch.cat(cluster_centroids, dim=0)\n",
    "    \n",
    "    # Ensure centroids are leaf tensors\n",
    "    main_centroids.requires_grad_(True)\n",
    "    cluster_centroids.requires_grad_(True)\n",
    "    \n",
    "    return main_centroids, cluster_centroids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "n_samples, n_features, n_classes, clusters_per_class = 100, 5, 3, 4\n",
    "train_data = torch.rand(n_samples, n_features)\n",
    "train_labels = torch.randint(0, n_classes, (n_samples,))\n",
    "    \n",
    "main_centroids, cluster_centroids = calculate_centroids(train_data, train_labels, clusters_per_class)\n",
    "print(\"Main Centroids:\\n\", main_centroids)\n",
    "print(\"Cluster Centroids:\\n\", cluster_centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "_kernel_optimizer = optim.SGD([\n",
    "            {'params': main_centroids, 'lr': 0.1},\n",
    "            {'params': cluster_centroids, 'lr': 0.1},\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m main_centroid\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m x_1 \u001b[38;5;241m=\u001b[39m class_centroids\n\u001b[0;32m----> 7\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/utils/model.py:59\u001b[0m, in \u001b[0;36mQkernel.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[0;32m---> 59\u001b[0m     all_zero_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_projector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_reuploading\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circuit_executions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_zero_state\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/pennylane/workflow/qnode.py:1020\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39mqnode_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/pennylane/workflow/qnode.py:1002\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m     override_shots \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[0;32m-> 1002\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1004\u001b[0m original_grad_fn \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_fn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice]\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn(shots\u001b[38;5;241m=\u001b[39moverride_shots, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape)\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/kgreedy/lib/python3.12/site-packages/pennylane/workflow/qnode.py:851\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pldb_device_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mqueuing\u001b[38;5;241m.\u001b[39mAnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m--> 851\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m    855\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/developer/greedy_kernel_alignment/utils/ansatz.py:73\u001b[0m, in \u001b[0;36mqkembedding_paper\u001b[0;34m(x1, x2, weights, wires, layers, projector, data_reuploading)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqkembedding_paper\u001b[39m(x1 , x2, weights, wires, layers, projector, data_reuploading):\n\u001b[0;32m---> 73\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[43mx1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(wires) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x1[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)[:, :\u001b[38;5;28mlen\u001b[39m(wires)]\n\u001b[1;32m     74\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(wires) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x2[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)[:, :\u001b[38;5;28mlen\u001b[39m(wires)]\n\u001b[1;32m     75\u001b[0m     _embedding_paper(x1,weights,wires,layers,data_reuploading)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "\n",
    "class_centroids = cluster_centroids[0]\n",
    "main_centroid = main_centroids[0]\n",
    "\n",
    "x_0 = main_centroid.repeat(4, 1)\n",
    "x_1 = class_centroids\n",
    "                \n",
    "K = kernel(x_0, x_1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgreedy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
